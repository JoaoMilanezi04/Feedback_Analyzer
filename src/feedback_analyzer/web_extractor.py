"""
MÃ³dulo para extrair comentÃ¡rios de produtos de diferentes plataformas web.
Suporta Amazon, MercadoLivre, Google Play, App Store e sites genÃ©ricos.
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd
import time
import re
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, WebDriverException
import json
from urllib.parse import urlparse


def configurar_driver():
    """Configura o driver do Chrome com opÃ§Ãµes otimizadas."""
    try:
        options = Options()
        options.add_argument('--headless')  # Executa em modo headless
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-gpu')
        options.add_argument('--window-size=1920,1080')
        options.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')
        
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        return driver
    except Exception as e:
        print(f"âš ï¸ Selenium nÃ£o disponÃ­vel: {e}")
        print("ğŸ“ Tentando extraÃ§Ã£o alternativa com requests...")
        return None


def extrair_amazon(driver, url):
    """Extrai comentÃ¡rios da Amazon."""
    comentarios = []
    
    try:
        driver.get(url)
        time.sleep(3)
        
        # Tentar encontrar o link de reviews
        try:
            reviews_link = driver.find_element(By.PARTIAL_LINK_TEXT, "customer reviews")
            reviews_link.click()
            time.sleep(3)
        except:
            # Se nÃ£o encontrar, tentar buscar reviews na pÃ¡gina atual
            pass
        
        # Extrair comentÃ¡rios
        review_elements = driver.find_elements(By.CSS_SELECTOR, "[data-hook='review-body'] span")
        
        for review in review_elements[:50]:  # Limitar a 50 comentÃ¡rios
            texto = review.text.strip()
            if texto and len(texto) > 10:
                comentarios.append(texto)
        
        print(f"âœ… Amazon: {len(comentarios)} comentÃ¡rios extraÃ­dos")
        
    except Exception as e:
        print(f"âŒ Erro ao extrair da Amazon: {e}")
    
    return comentarios


def extrair_mercadolivre(driver, url):
    """Extrai comentÃ¡rios do MercadoLivre."""
    comentarios = []
    
    try:
        driver.get(url)
        time.sleep(3)
        
        # Tentar clicar na aba de opiniÃµes
        try:
            opinions_tab = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, "//a[contains(text(), 'OpiniÃµes') or contains(text(), 'Opiniones')]"))
            )
            opinions_tab.click()
            time.sleep(3)
        except:
            print("âš ï¸ NÃ£o foi possÃ­vel encontrar a aba de opiniÃµes")
        
        # Extrair comentÃ¡rios com diferentes seletores
        selectors = [
            ".ui-review-view__comment",
            ".ui-review-capability-comments__comment__text",
            "[class*='review'] [class*='comment']",
            ".review-text",
            ".opinion-text"
        ]
        
        for selector in selectors:
            review_elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if review_elements:
                break
        
        for review in review_elements[:50]:  # Limitar a 50 comentÃ¡rios
            texto = review.text.strip()
            if texto and len(texto) > 10:
                comentarios.append(texto)
        
        print(f"âœ… MercadoLivre: {len(comentarios)} comentÃ¡rios extraÃ­dos")
        
    except Exception as e:
        print(f"âŒ Erro ao extrair do MercadoLivre: {e}")
    
    return comentarios


def extrair_google_play(driver, url):
    """Extrai reviews do Google Play."""
    comentarios = []
    
    try:
        driver.get(url)
        time.sleep(3)
        
        # Scroll para carregar mais reviews
        for _ in range(3):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(2)
        
        # Extrair reviews
        review_elements = driver.find_elements(By.CSS_SELECTOR, "[jsname='bN97Pc']")
        
        for review in review_elements[:50]:
            texto = review.text.strip()
            if texto and len(texto) > 10:
                comentarios.append(texto)
        
        print(f"âœ… Google Play: {len(comentarios)} reviews extraÃ­dos")
        
    except Exception as e:
        print(f"âŒ Erro ao extrair do Google Play: {e}")
    
    return comentarios


def extrair_app_store(url):
    """Extrai reviews do App Store usando requests (sem Selenium)."""
    comentarios = []
    
    try:
        # O App Store tem uma API diferente, vamos tentar uma abordagem bÃ¡sica
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        
        response = requests.get(url, headers=headers)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Tentar encontrar reviews (o App Store Ã© mais complexo)
        review_elements = soup.find_all(['p', 'div'], class_=re.compile('review|comment'))
        
        for review in review_elements[:20]:
            texto = review.get_text().strip()
            if texto and len(texto) > 10:
                comentarios.append(texto)
        
        print(f"âœ… App Store: {len(comentarios)} reviews extraÃ­dos")
        
    except Exception as e:
        print(f"âŒ Erro ao extrair do App Store: {e}")
    
    return comentarios


def extrair_generico(driver, url):
    """Extrai comentÃ¡rios de sites genÃ©ricos."""
    comentarios = []
    
    try:
        driver.get(url)
        time.sleep(3)
        
        # Seletores genÃ©ricos para comentÃ¡rios
        selectors = [
            "[class*='comment']",
            "[class*='review']",
            "[class*='feedback']",
            "[class*='opinion']",
            ".comment-text",
            ".review-text",
            ".user-comment",
            ".customer-review"
        ]
        
        for selector in selectors:
            review_elements = driver.find_elements(By.CSS_SELECTOR, selector)
            if review_elements:
                for review in review_elements[:30]:
                    texto = review.text.strip()
                    if texto and len(texto) > 10:
                        comentarios.append(texto)
                if comentarios:
                    break
        
        print(f"âœ… Site genÃ©rico: {len(comentarios)} comentÃ¡rios extraÃ­dos")
        
    except Exception as e:
        print(f"âŒ Erro ao extrair do site genÃ©rico: {e}")
    
    return comentarios


def identificar_plataforma(url):
    """Identifica a plataforma baseada na URL."""
    url_lower = url.lower()
    domain = urlparse(url).netloc.lower()
    
    if 'amazon' in domain:
        return 'amazon'
    elif 'mercadolivre' in domain or 'mercadolibre' in domain:
        return 'mercadolivre'
    elif 'play.google.com' in domain:
        return 'google_play'
    elif 'apps.apple.com' in domain:
        return 'app_store'
    else:
        return 'generico'


def extrair_comentarios_de_url(url):
    """
    FunÃ§Ã£o principal para extrair comentÃ¡rios de uma URL.
    
    Args:
        url (str): URL do produto/aplicativo
    
    Returns:
        pandas.DataFrame: DataFrame com os comentÃ¡rios extraÃ­dos
    """
    print(f"ğŸŒ Extraindo comentÃ¡rios de: {url}")
    
    plataforma = identificar_plataforma(url)
    print(f"ğŸ“± Plataforma detectada: {plataforma.title()}")
    
    comentarios = []
    
    # Tentar primeiro com Selenium (mais eficiente)
    driver = configurar_driver()
    
    if driver:
        print("ğŸ¤– Usando Selenium para extraÃ§Ã£o...")
        try:
            if plataforma == 'amazon':
                comentarios = extrair_amazon(driver, url)
            elif plataforma == 'mercadolivre':
                comentarios = extrair_mercadolivre(driver, url)
            elif plataforma == 'google_play':
                comentarios = extrair_google_play(driver, url)
            elif plataforma == 'app_store':
                comentarios = extrair_app_store(url)
            else:
                comentarios = extrair_generico(driver, url)
        
        finally:
            driver.quit()
    
    # Se Selenium falhou ou nÃ£o estÃ¡ disponÃ­vel, usar requests
    if not comentarios:
        print("ğŸŒ Tentando extraÃ§Ã£o alternativa com requests...")
        comentarios = extrair_com_requests(url)
    
    if not comentarios:
        print("âš ï¸ Nenhum comentÃ¡rio foi extraÃ­do. PossÃ­veis causas:")
        print("  â€¢ O site pode ter proteÃ§Ã£o anti-bot")
        print("  â€¢ A estrutura da pÃ¡gina pode ter mudado")
        print("  â€¢ O produto pode nÃ£o ter comentÃ¡rios")
        print("  â€¢ Sua conexÃ£o pode estar instÃ¡vel")
        print("  â€¢ Chrome nÃ£o estÃ¡ instalado (para Selenium)")
        return pd.DataFrame()
    
    # Criar DataFrame
    df = pd.DataFrame({'comentario': comentarios})
    
    # Limpar e filtrar comentÃ¡rios
    df['comentario'] = df['comentario'].str.strip()
    df = df[df['comentario'].str.len() > 10]  # Remover comentÃ¡rios muito curtos
    df = df.drop_duplicates('comentario')  # Remover duplicatas
    df = df.reset_index(drop=True)
    
    print(f"âœ… Total de comentÃ¡rios Ãºnicos extraÃ­dos: {len(df)}")
    
    return df


def salvar_comentarios(df, arquivo='comentarios_extraidos.csv'):
    """Salva os comentÃ¡rios extraÃ­dos em um arquivo."""
    try:
        df.to_csv(arquivo, index=False, encoding='utf-8')
        print(f"ğŸ’¾ ComentÃ¡rios salvos em: {arquivo}")
    except Exception as e:
        print(f"âŒ Erro ao salvar: {e}")


def extrair_com_requests(url):
    """ExtraÃ§Ã£o alternativa usando apenas requests e BeautifulSoup."""
    comentarios = []
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'pt-BR,pt;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }
        
        session = requests.Session()
        session.headers.update(headers)
        
        print("ğŸŒ Fazendo requisiÃ§Ã£o HTTP...")
        response = session.get(url, timeout=15)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # Tentar diferentes seletores para encontrar comentÃ¡rios/reviews
        selectors = [
            # MercadoLivre
            '.ui-review-view__comment',
            '.ui-review-capability-comments__comment__text',
            '[class*="review"] [class*="comment"]',
            '[class*="opinion"]',
            
            # Amazon
            '[data-hook="review-body"] span',
            '.review-text',
            '.cr-original-review-text',
            
            # GenÃ©ricos
            '[class*="comment"]',
            '[class*="review"]',
            '[class*="feedback"]',
            '.comment-text',
            '.review-content',
            '.user-review',
            '.customer-review'
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                print(f"âœ… Encontrados elementos com seletor: {selector}")
                for element in elements[:30]:  # Limitar a 30
                    text = element.get_text().strip()
                    if text and len(text) > 15 and len(text) < 1000:  # Filtrar textos muito curtos ou longos
                        comentarios.append(text)
                
                if comentarios:
                    break
        
        # Se nÃ£o encontrou com seletores especÃ­ficos, tentar busca por texto
        if not comentarios:
            print("ğŸ” Tentando busca por texto...")
            all_text = soup.get_text()
            # Procurar por padrÃµes comuns de reviews
            patterns = [
                r'(?i)(?:excelente|Ã³timo|bom|ruim|pÃ©ssimo|recomendo|nÃ£o recomendo).{10,200}',
                r'(?i)(?:produto|app|aplicativo|serviÃ§o).{10,200}',
                r'(?i)(?:comprei|usei|testei|instalei).{10,200}'
            ]
            
            for pattern in patterns:
                matches = re.findall(pattern, all_text)
                for match in matches[:10]:  # Limitar a 10 por padrÃ£o
                    if len(match.strip()) > 15:
                        comentarios.append(match.strip())
        
        print(f"ğŸ“ ExtraÃ§Ã£o com requests: {len(comentarios)} comentÃ¡rios encontrados")
        
    except requests.exceptions.RequestException as e:
        print(f"âŒ Erro na requisiÃ§Ã£o HTTP: {e}")
    except Exception as e:
        print(f"âŒ Erro na extraÃ§Ã£o com requests: {e}")
    
    return comentarios


if __name__ == "__main__":
    # Teste da extraÃ§Ã£o
    url_teste = input("Digite a URL para teste: ")
    comentarios_df = extrair_comentarios_de_url(url_teste)
    
    if not comentarios_df.empty:
        print(f"\nğŸ“Š Primeiros 5 comentÃ¡rios:")
        for i, comentario in enumerate(comentarios_df['comentario'].head(), 1):
            print(f"{i}. {comentario[:100]}...")
        
        salvar = input("\nDeseja salvar os comentÃ¡rios? (s/n): ").lower().strip()
        if salvar == 's':
            salvar_comentarios(comentarios_df)
